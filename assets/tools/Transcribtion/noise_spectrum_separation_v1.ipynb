{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNEYXiMkOQIxKu4Ya8qbMV/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["What I did (concise):\n","\n","Converted your 60s-20.m4a to WAV inside the workspace.\n","\n","Computed an STFT of the mixture.\n","\n","Performed a fast NMF-based source separation on a reduced (downsampled) spectrogram to keep runtime manageable.\n","\n","Reconstructed 3 separated components (automatic selection geared toward speed/robustness).\n","\n","Saved each separated component as a WAV file and plotted the overlayed normalized waveforms and spectrograms inside the notebook.\n","\n","Files I produced (download from these links):\n","\n","\n","Important notes and limitations (please read):\n","\n","To keep the process fast and reliable in this environment I downsampled the spectrogram and ran a relatively fast NMF (3 components). That produces useful, approximate separations (good for isolating prominent sources like voices, music, hums), but it is not a perfect blind source separation. More components or different algorithms (e.g., Spleeter, Open-Unmix, Conv-TasNet, or running full-resolution NMF/ICA) will often yield better separation but take substantially longer and need more compute.\n","\n","I intentionally used a soft-mask approach (component magnitude / sum of magnitudes) and applied the original complex STFT phase during reconstruction — a standard practical method, but it inherits mixture phase which can limit clarity of fully-separated sources.\n","\n","If you want stronger separation (more components, or separation tuned to speech/music/clicks), I can:\n","\n","re-run with more components (e.g., 4–6) or a different algorithm (Spleeter/Open-Unmix) — this will take longer;\n","\n","or run a two-stage approach (denoise/speech enhancement first, then NMF) which often improves quality.\n","\n","I did not label the components automatically (e.g., \"voice\" vs \"music\"). If you want, I can analyze each component's spectral / temporal features and guess labels (speech/music/low hum/clicks) and return that.\n","\n","If you'd like any of the following next steps, tell me which one and I’ll proceed immediately:\n","\n","Re-run separation with more components (4–6) for finer separation.\n","\n","Try a different separation model (Spleeter/Open-Unmix) for better quality (takes longer).\n","\n","Auto-label each component (speech / music / noise / hum / click) and give timestamps where each dominates.\n","\n","Produce ZIP with all separated WAVs and short preview MP3s."],"metadata":{"id":"9msFQIu1mtuI"}},{"cell_type":"markdown","source":["## Importing modules"],"metadata":{"id":"QT2Gr4JjeH-I"}},{"cell_type":"code","source":["import os, subprocess, numpy as np, matplotlib.pyplot as plt\n","from scipy import signal\n","import soundfile as sf\n","from sklearn.decomposition import NMF"],"metadata":{"id":"UV_7Xy_jeI5v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## File pathes"],"metadata":{"id":"WVMNPWXNeNQR"}},{"cell_type":"code","source":["m4a = '/content/60s-20.m4a'\n","wav = '/content/60s-20_converted.wav'\n","print(\"m4a exists:\", os.path.exists(m4a))\n","if os.path.exists(wav):\n","    print(\"Removing previous wav:\", wav)\n","    os.remove(wav)"],"metadata":{"id":"Q0LH2UM1eOuv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Running ffmpeg to convert (silently)"],"metadata":{"id":"nceLGljYeWEQ"}},{"cell_type":"code","source":["res = subprocess.run(['ffmpeg', '-y', '-i', m4a, wav], capture_output=True, text=True)\n","print(\"ffmpeg returncode:\", res.returncode)\n","if res.returncode != 0:\n","    print(\"ffmpeg stderr:\", res.stderr[:1000])\n","    raise RuntimeError(\"ffmpeg failed to convert the file\")\n","\n","print(\"Converted file exists:\", os.path.exists(wav))"],"metadata":{"id":"FzX3up1heZSP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Loading converted wav format"],"metadata":{"id":"OgUnMYKeeovy"}},{"cell_type":"code","source":["y, sr = sf.read(wav)\n","if y.ndim > 1:\n","    y = np.mean(y, axis=1)\n","y = y.astype(np.float32)\n","duration = len(y) / sr\n","print(f\"Loaded '{wav}' — duration: {duration:.2f}s, sample rate: {sr} Hz, samples: {len(y)}\")"],"metadata":{"id":"JK7EHG_4erd_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Running a Short-Time Fourier Transform (STFT)"],"metadata":{"id":"ig0p5egLmHw_"}},{"cell_type":"code","source":["# STFT\n","n_fft = 2048\n","hop_length = 512\n","f, t, Zxx = signal.stft(y, fs=sr, nperseg=n_fft, noverlap=n_fft-hop_length, boundary=None)\n","S = np.abs(Zxx)\n","print(\"STFT shape:\", S.shape)"],"metadata":{"id":"EIb6z9HmfhoS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Running a Non-negative Matrix Factorization (NMF) for separation"],"metadata":{"id":"MW2HGSaAmN7j"}},{"cell_type":"code","source":["# NMF components search\n","S_max = S.max() if S.max() > 0 else 1.0\n","S_norm = S / S_max + 1e-10\n","recons_scores = {}\n","for n_comp in range(2,7):\n","    model = NMF(n_components=n_comp, init='nndsvda', solver='mu', beta_loss='kullback-leibler', max_iter=500, random_state=0)\n","    W = model.fit_transform(S_norm)\n","    H = model.components_\n","    S_approx = np.dot(W,H)\n","    err = np.linalg.norm(S_norm - S_approx, ord='fro')\n","    fit = 1 - (err / np.linalg.norm(S_norm, ord='fro'))\n","    recons_scores[n_comp] = fit\n","    print(f\"n={n_comp} fit={fit:.4f}\")"],"metadata":{"id":"s_omoh4cfjWM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# choose best n with diminishing returns\n","prev = None\n","best_n = 6\n","for n, fit in sorted(recons_scores.items()):\n","    if prev is not None:\n","        if fit - prev < 0.02:\n","            best_n = n\n","            break\n","    prev = fit\n","print(\"Chosen components:\", best_n)"],"metadata":{"id":"qzQoIPm5flLq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# recompute NMF for best_n\n","model = NMF(n_components=best_n, init='nndsvda', solver='mu', beta_loss='kullback-leibler', max_iter=500, random_state=0)\n","W = model.fit_transform(S_norm); H = model.components_\n","components_S = []\n","for k in range(best_n):\n","    comp = np.outer(W[:,k], H[k,:]) * S_max\n","    components_S.append(comp)\n","components_S = np.array(components_S)"],"metadata":{"id":"V8Ij1dU7fmdm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# masks and reconstruction\n","eps = 1e-10\n","sum_S = np.sum(components_S, axis=0) + eps\n","masks = components_S / sum_S\n","reconstructed = []\n","out_files = []\n","import soundfile as sf\n","for k in range(best_n):\n","    masked = masks[k] * Zxx\n","    _, y_comp = signal.istft(masked, fs=sr, nperseg=n_fft, noverlap=n_fft-hop_length, input_onesided=True)\n","    y_comp = y_comp[:len(y)]\n","    reconstructed.append(y_comp)\n","    outp = f\"/content/60s-20_component_{k+1}.wav\"\n","    sf.write(outp, y_comp, sr)\n","    out_files.append(outp)\n","\n","print(\"Saved outputs:\", out_files)"],"metadata":{"id":"uPErdUXDfn4q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Overlaying plots"],"metadata":{"id":"r8g9ZsDpmVfv"}},{"cell_type":"code","source":["# Plot overlayed waveforms\n","plt.figure(figsize=(12,6))\n","t_axis = np.arange(len(y)) / sr\n","plt.plot(t_axis, y / (np.max(np.abs(y)) + 1e-9), alpha=0.25, linewidth=0.8, label='mixture (normalized)')\n","for k, sig in enumerate(reconstructed):\n","    if np.max(np.abs(sig)) > 0:\n","        sign = sig / np.max(np.abs(sig))\n","    else:\n","        sign = sig\n","    # Create t_axis based on the length of the current signal\n","    t_axis_comp = np.arange(len(sign)) / sr\n","    plt.plot(t_axis_comp, sign, linewidth=1, label=f'component {k+1}')\n","plt.xlabel('Time (s)'); plt.ylabel('Amplitude (normalized)')\n","plt.title('Overlayed waveforms: separated components (normalized)')\n","plt.legend(loc='upper right', fontsize='small')\n","plt.xlim(0, duration)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"QB1vSGhTfpUe"},"execution_count":null,"outputs":[]}]}